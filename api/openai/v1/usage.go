package v1

// Usage represents usage statistics for the completion request.
// These statistics help track token consumption for billing and context window management.
type Usage struct {
	// PromptTokens is the number of tokens in the prompt.
	// +required
	PromptTokens int `json:"prompt_tokens"`

	// CompletionTokens is the number of tokens in the generated completion.
	// +required
	CompletionTokens int `json:"completion_tokens"`

	// TotalTokens is the total number of tokens used in the request (prompt + completion).
	// +required
	TotalTokens int `json:"total_tokens"`

	// PromptTokensDetails provides a breakdown of tokens used in the prompt.
	// +optional
	PromptTokensDetails *PromptTokensDetails `json:"prompt_tokens_details,omitempty"`

	// CompletionTokensDetails provides a breakdown of tokens used in a completion.
	// +optional
	CompletionTokensDetails *CompletionTokensDetails `json:"completion_tokens_details,omitempty"`
}

// CompletionTokensDetails provides a breakdown of tokens used in a completion.
type CompletionTokensDetails struct {
	// AudioTokens represents audio input tokens generated by the model.
	// +optional
	AudioTokens *int `json:"audio_tokens,omitempty"`

	// ReasoningTokens represents tokens generated by the model for reasoning.
	// +optional
	ReasoningTokens *int `json:"reasoning_tokens,omitempty"`

	// AcceptedPredictionTokens represents the number of tokens in the prediction that appeared in the completion.
	// When using Predicted Outputs, these are tokens that matched the predicted content.
	// +optional
	AcceptedPredictionTokens *int `json:"accepted_prediction_tokens,omitempty"`

	// RejectedPredictionTokens represents the number of tokens in the prediction that did not appear in the completion.
	// However, like reasoning tokens, these tokens are still counted in the total completion tokens
	// for purposes of billing, output, and context window limits.
	// +optional
	RejectedPredictionTokens *int `json:"rejected_prediction_tokens,omitempty"`
}

// PromptTokensDetails provides a breakdown of tokens used in the prompt.
type PromptTokensDetails struct {
	// AudioTokens represents audio input tokens present in the prompt.
	// +optional
	AudioTokens *int `json:"audio_tokens"`

	// CachedTokens represents cached tokens present in the prompt.
	// +optional
	CachedTokens *int `json:"cached_tokens"`
}
